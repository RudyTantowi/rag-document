{
  "name": "RAG Chat Workflow Simple",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "chat",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "webhook-chat",
      "name": "Webhook Chat",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1.1,
      "position": [240, 300],
      "webhookId": "rag-chat-webhook"
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "url": "https://router.huggingface.co/hf-inference/models/sentence-transformers/all-MiniLM-L6-v2/pipeline/feature-extraction",
        "method": "POST",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ { \"inputs\": $json.body?.message || $json.message } }}",
        "options": {
          "responseFormat": "text"
        }
      },
      "id": "huggingface-query-embedding",
      "name": "HuggingFace Query Embedding",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [460, 300],
      "credentials": {
        "httpHeaderAuth": {
          "id": "1",
          "name": "HuggingFace API"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Parse HuggingFace response format: {data: \"[x,y,z,...]\"}\nconst response = $input.item.json;\nlet embedding;\n\nif (typeof response === 'string') {\n  const parsed = JSON.parse(response);\n  embedding = JSON.parse(parsed.data);\n} else if (response.data) {\n  embedding = typeof response.data === 'string' ? JSON.parse(response.data) : response.data;\n} else {\n  embedding = Array.isArray(response) ? response : [];\n}\n\nconst webhookData = $('Webhook Chat').item.json;\n\n// Return data properly without wrapping in array to maintain item pairing\nreturn {\n  json: {\n    query_embedding: embedding,\n    file_id: webhookData.body?.file_id || webhookData.file_id,\n    message: webhookData.body?.message || webhookData.message\n  }\n};"
      },
      "id": "code-extract-embedding",
      "name": "Extract Embedding",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [680, 300]
    },
    {
      "parameters": {
        "url": "={{ \"https://ankdhneeohlknstgloyy.supabase.co/rest/v1/document_chunks?file_id=eq.\" + $json.file_id + \"&select=id,file_id,filename,chunk_index,chunk_text,embedding\" }}",
        "method": "GET",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "apikey",
              "value": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImFua2RobmVlb2hsa25zdGdsb3l5Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzcxNzc4NDAsImV4cCI6MjA1Mjc1Mzg0MH0.Bkjj4tNW0-hZ4yCRuWM2FhgJ6G1W-7IhA8Iy06i1TIs"
            },
            {
              "name": "Authorization",
              "value": "Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImFua2RobmVlb2hsa25zdGdsb3l5Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzcxNzc4NDAsImV4cCI6MjA1Mjc1Mzg0MH0.Bkjj4tNW0-hZ4yCRuWM2FhgJ6G1W-7IhA8Iy06i1TIs"
            }
          ]
        },
        "options": {}
      },
      "id": "supabase-get-chunks",
      "name": "Get All Chunks",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [900, 300]
    },
    {
      "parameters": {
        "jsCode": "// Calculate cosine similarity and get top 5 chunks\nconst queryEmbedding = $('Extract Embedding').item.json.query_embedding;\nconst chunks = $input.item.json;\nconst userMessage = $('Webhook Chat').item.json.body?.message || $('Webhook Chat').item.json.message;\nconst fileId = $('Extract Embedding').item.json.file_id;\n\n// Function to calculate cosine similarity\nfunction cosineSimilarity(a, b) {\n  let dotProduct = 0;\n  let normA = 0;\n  let normB = 0;\n  \n  for (let i = 0; i < a.length; i++) {\n    dotProduct += a[i] * b[i];\n    normA += a[i] * a[i];\n    normB += b[i] * b[i];\n  }\n  \n  return dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));\n}\n\n// Calculate similarity for each chunk\nconst chunksWithSimilarity = chunks.map(chunk => {\n  // Parse embedding from string format \"[x,y,z,...]\"\n  const embedding = JSON.parse(chunk.embedding);\n  const similarity = cosineSimilarity(queryEmbedding, embedding);\n  \n  return {\n    ...chunk,\n    similarity\n  };\n});\n\n// Sort by similarity (descending) and take top 5\nconst topChunks = chunksWithSimilarity\n  .sort((a, b) => b.similarity - a.similarity)\n  .slice(0, 5)\n  .sort((a, b) => a.chunk_index - b.chunk_index); // Then sort by index for reading order\n\n// Combine text\nconst context = topChunks.map(c => c.chunk_text).join('\\n\\n');\n\nconst systemPrompt = \"Anda adalah asisten AI yang membantu menjawab pertanyaan berdasarkan dokumen yang diberikan. Jawab dengan jelas dan akurat berdasarkan konteks yang tersedia. Jika informasi tidak ada dalam konteks, katakan dengan jujur bahwa Anda tidak menemukan informasi tersebut dalam dokumen.\";\n\nconst userPrompt = `Context dari dokumen:\\n${context}\\n\\nPertanyaan: ${userMessage}\\n\\nJawab berdasarkan context di atas:`;\n\nreturn [{\n  json: {\n    system_prompt: systemPrompt,\n    user_prompt: userPrompt,\n    original_message: userMessage,\n    file_id: fileId,\n    chunks_used: topChunks.length,\n    top_similarities: topChunks.map(c => c.similarity)\n  }\n}];"
      },
      "id": "code-calculate-similarity",
      "name": "Calculate Similarity",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1120, 300]
    },
    {
      "parameters": {
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "url": "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent",
        "method": "POST",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ {\n  \"contents\": [{\n    \"parts\": [{\n      \"text\": $json.system_prompt + \"\\n\\n\" + $json.user_prompt\n    }]\n  }],\n  \"generationConfig\": {\n    \"temperature\": 0.3,\n    \"maxOutputTokens\": 1000\n  }\n} }}",
        "options": {}
      },
      "id": "gemini-chat",
      "name": "Gemini Chat",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [1340, 300],
      "credentials": {
        "httpHeaderAuth": {
          "id": "2",
          "name": "Google Gemini API"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Extract Gemini response\nconst response = $input.item.json;\nconst aiMessage = response.candidates?.[0]?.content?.parts?.[0]?.text || 'No response generated';\n\nconst originalMessage = $('Calculate Similarity').item.json.original_message;\nconst fileId = $('Calculate Similarity').item.json.file_id;\nconst chunksUsed = $('Calculate Similarity').item.json.chunks_used;\n\nreturn [{\n  json: {\n    message: aiMessage,\n    original_question: originalMessage,\n    file_id: fileId,\n    chunks_used: chunksUsed,\n    model: 'gemini-1.5-flash'\n  }\n}];"
      },
      "id": "code-format-response",
      "name": "Format Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1560, 300]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ $json }}"
      },
      "id": "respond-webhook-chat",
      "name": "Respond to Webhook",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [1780, 300]
    }
  ],
  "connections": {
    "Webhook Chat": {
      "main": [
        [
          {
            "node": "HuggingFace Query Embedding",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "HuggingFace Query Embedding": {
      "main": [
        [
          {
            "node": "Extract Embedding",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Embedding": {
      "main": [
        [
          {
            "node": "Get All Chunks",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get All Chunks": {
      "main": [
        [
          {
            "node": "Calculate Similarity",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Calculate Similarity": {
      "main": [
        [
          {
            "node": "Gemini Chat",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Gemini Chat": {
      "main": [
        [
          {
            "node": "Format Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format Response": {
      "main": [
        [
          {
            "node": "Respond to Webhook",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "pinData": {},
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "tags": [],
  "triggerCount": 0,
  "updatedAt": "2026-01-18T00:00:00.000Z",
  "versionId": "1"
}
